{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_folder=os.path.normcase(r'C:\\Users\\dell\\Downloads\\Titanic-maching-learning-from-disaster')\n",
    "train_data=pd.read_csv(os.path.join(path_folder,'train.csv'),sep=',')\n",
    "test_data_origin=pd.read_csv(os.path.join(path_folder,'test.csv'),sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deal_ticket_fare(df):\n",
    "    '''\n",
    "    计算每张票有几人共享，以及每人花费的船票钱\n",
    "    \n",
    "    paramters:\n",
    "        df--dataframe，待处理的数据表\n",
    "        \n",
    "    return:\n",
    "        df_count--处理后，添加新列的数据表\n",
    "    '''\n",
    "    num_of_tickets=df[['Ticket']].groupby(df['Ticket']).count()\n",
    "    num_of_tickets.columns=['num_of_tickets']\n",
    "    df_count=df.merge(num_of_tickets,left_on='Ticket',right_index=True,how='left')\n",
    "    df_count['fare_per_ticket']=df_count['Fare']/df_count['num_of_tickets']\n",
    "    return df_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 构造 数据预处理 流水线\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline,FeatureUnion\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator,TransformerMixin\n",
    "\n",
    "class DataFrameSelector(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self,attrs_name_list):\n",
    "        self.attrs_name_list=attrs_name_list\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    def transform(self,X):\n",
    "        return X[self.attrs_name_list].values\n",
    "\n",
    "def data_preparation(cat_attributes,interval_num_attributes,ratio_num_attributes):\n",
    "    '''\n",
    "    构造处理DataFrame 的 类\n",
    "    \n",
    "    Arguments:\n",
    "        cat_attributes ---         标称数据列集合\n",
    "        interval_num_attributes--- 标度数值列集合/不需进行标准化的列集合\n",
    "        ratio_num_attributes   --- 比例数值列集合/需进行 标准化 列集合\n",
    "       \n",
    "    Return \n",
    "        full_pipeline---类class\n",
    "    '''\n",
    "    cat_attrs=cat_attributes    \n",
    "    interval_num_attrs=interval_num_attributes\n",
    "    ratio_num_attrs=ratio_num_attributes\n",
    "    transformer_list=[]\n",
    "    \n",
    "    if cat_attrs:\n",
    "        cat_pipeline=Pipeline([('cat_dfs',DataFrameSelector(cat_attrs)),('impute',SimpleImputer(strategy='most_frequent')),\\\n",
    "                               ('onehotencoder',OneHotEncoder())])\n",
    "        transformer_list.append(('cat_pipeline',cat_pipeline))\n",
    "        \n",
    "    if interval_num_attrs:\n",
    "        interval_num_pipeline=Pipeline([('dfs',DataFrameSelector(interval_num_attrs)),('impute',SimpleImputer(strategy='median')) ])\n",
    "        transformer_list.append(('interval_num_pipeline',interval_num_pipeline))\n",
    "        \n",
    "    if ratio_num_attrs:    \n",
    "        ratio_num_pipeline=Pipeline([('dfs',DataFrameSelector(ratio_num_attrs)),('impute',SimpleImputer(strategy='median')),\\\n",
    "                                     ('std_scaler',StandardScaler())])\n",
    "        transformer_list.append(('ratio_num_pipeline',ratio_num_pipeline))\n",
    "    full_pipeline=FeatureUnion(transformer_list=transformer_list)\n",
    "    return full_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,n_jobs=None, train_sizes=np.linspace(0.1, 1.0, 10)):\n",
    "    from sklearn.model_selection import learning_curve\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)#train_scores size (n_ticks,n_cv_folds)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 's-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 计算 预测准确率\n",
    "def compute_acc(y,y_pred):\n",
    "    y_pred_class=np.where(y_pred>=0.5,1,0)\n",
    "    pred_accuracy=(y==y_pred_class).sum()/len(y)    \n",
    "    return pred_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  1.        ,  0.        ,  0.        ,  1.        ,\n",
       "        1.        ,  0.        ,  2.        ,  1.        , -1.91971935,\n",
       "        0.98099823,  3.53619915])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scale 数值数据 数据预处理\n",
    "train_data_count=deal_ticket_fare(train_data)\n",
    "from sklearn.model_selection import train_test_split\n",
    "#train_data_index,dev_data_index=train_test_split(train_data_count.index.tolist(),train_size=0.7,test_size=0.3,random_state=42)\n",
    "#train_df_data=train_data_count.iloc[train_data_index,:]\n",
    "#dev_df_data=train_data_count.iloc[dev_data_index,:]\n",
    "train_df_data,dev_df_data=train_test_split(train_data_count,train_size=0.7,test_size=0.3,random_state=42)\n",
    "train_data_index=train_df_data.index.tolist()\n",
    "dev_data_index=dev_df_data.index.tolist()\n",
    "cat_attrs=['Sex','Embarked']    \n",
    "interval_num_attrs=['Pclass','SibSp','Parch','num_of_tickets']\n",
    "ratio_num_attrs=['Age','Fare','fare_per_ticket']\n",
    "full_pipeline_std=data_preparation(cat_attrs,interval_num_attrs,ratio_num_attrs)\n",
    "train_data_X=full_pipeline_std.fit_transform(train_df_data).toarray()\n",
    "train_data_y=train_df_data['Survived'].values.ravel()\n",
    "train_data_X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols=['Sex_T','Embarked_T','Age','Fare','fare_per_ticket','num_of_tickets','Pclass','SibSp','Parch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>num_of_tickets</th>\n",
       "      <th>fare_per_ticket</th>\n",
       "      <th>Sex_T</th>\n",
       "      <th>Embarked_T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>7.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass                     Name   Sex   Age  SibSp  \\\n",
       "0            1         0       3  Braund, Mr. Owen Harris  male  22.0      1   \n",
       "\n",
       "   Parch     Ticket  Fare Cabin Embarked  num_of_tickets  fare_per_ticket  \\\n",
       "0      0  A/5 21171  7.25   NaN        S               1             7.25   \n",
       "\n",
       "   Sex_T  Embarked_T  \n",
       "0      0           0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_count.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 16 columns):\n",
      "PassengerId        891 non-null int64\n",
      "Survived           891 non-null int64\n",
      "Pclass             891 non-null int64\n",
      "Name               891 non-null object\n",
      "Sex                891 non-null object\n",
      "Age                891 non-null float64\n",
      "SibSp              891 non-null int64\n",
      "Parch              891 non-null int64\n",
      "Ticket             891 non-null object\n",
      "Fare               891 non-null float64\n",
      "Cabin              204 non-null object\n",
      "Embarked           891 non-null object\n",
      "num_of_tickets     891 non-null int64\n",
      "fare_per_ticket    891 non-null float64\n",
      "Sex_T              891 non-null int64\n",
      "Embarked_T         891 non-null int32\n",
      "dtypes: float64(3), int32(1), int64(7), object(5)\n",
      "memory usage: 108.0+ KB\n"
     ]
    }
   ],
   "source": [
    "#train_data_count=deal_ticket_fare(train_data)\n",
    "train_data_count.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#  categorical type data\n",
    "trans_sex={'male':0,'female':1}\n",
    "trans_embarked={'S':0,'C':1,'Q':2}\n",
    "train_data_count['Sex_T']=train_data_count['Sex'].map(trans_sex)\n",
    "#from sklearn.impute import MissingIndicator\n",
    "#indicator=MissingIndicator(missing_values=np.nan)\n",
    "#train_missing_indicator=indicator.fit_transform(train_data_count)\n",
    "from sklearn.impute import SimpleImputer\n",
    "imp1=SimpleImputer(missing_values=np.nan,strategy='most_frequent')\n",
    "train_data_count['Embarked']=imp1.fit_transform(train_data_count[['Embarked']])\n",
    "imp2=SimpleImputer(missing_values=np.nan,strategy='mean')\n",
    "train_data_count['Age']=imp2.fit_transform(train_data_count[['Age']])\n",
    "train_data_count['Embarked_T']=train_data_count['Embarked'].map(trans_embarked).astype(np.int)\n",
    "cols=['Sex_T','Embarked_T','Age','Fare','fare_per_ticket','num_of_tickets','Pclass','SibSp','Parch']\n",
    "X_train_data=train_data_count.reindex(columns=cols).values\n",
    "y_train_data=train_data_count['Survived'].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data_count=deal_ticket_fare(test_data_origin)\n",
    "test_data_X=full_pipeline_std.transform(test_data_count).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
       "        3.        ,  1.        ,  1.        ,  2.        , -0.0772525 ,\n",
       "       -0.32547755, -0.49449441])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_data_X=full_pipeline_std.transform(dev_df_data).toarray()\n",
    "dev_data_y=dev_df_data['Survived'].values.ravel()\n",
    "dev_data_X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "# 准备数据\n",
    "train_data=lgb.Dataset(train_data_X,train_data_y)\n",
    "valid_data=lgb.Dataset(dev_data_X,dev_data_y,reference=train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setting parameters  dict type\n",
    "param={'num_leaves':14,'num_iterations':40,'objective':'binary'}\n",
    "param['metric']='binary_error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setting parameters  dict type\n",
    "param={'num_leaves':15,'num_iterations':154,'objective':'binary'}\n",
    "param['metric']='binary_error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:116: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's binary_error: 0.186567\n",
      "[100]\tvalid_0's binary_error: 0.197761\n",
      "[150]\tvalid_0's binary_error: 0.19403\n"
     ]
    }
   ],
   "source": [
    "# training \n",
    "num_boost_round=10\n",
    "bst=lgb.train(param,train_data,num_boost_round,valid_sets=[valid_data],verbose_eval=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst.num_trees()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8585858585858586"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pred_y=bst.predict(data_X_train)\n",
    "compute_acc(data_y_train,train_pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8097014925373134"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_y_pred=bst.predict(dev_data_X)\n",
    "compute_acc(dev_data_y,dev_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_y_pred=bst.predict(test_data_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data_origin['Survived']=np.where(test_y_pred>=0.5,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data_origin[['PassengerId','Survived']].to_csv('c:/users/dell/desktop/gender_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metric': 'binary_error', 'num_leaves': 15, 'objective': 'binary'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  1.        ,  0.        ,  0.        ,  1.        ,\n",
       "        3.        ,  1.        ,  0.        ,  1.        , -0.56573646,\n",
       "       -0.50244517, -0.49697568])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scikit api 参数调优\n",
    "data_X_train=full_pipeline_std.fit_transform(train_data_count).toarray()\n",
    "data_y_train=train_data_count['Survived'].values.ravel()\n",
    "data_X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\tcv_agg's binary_error: 0.189645 + 0.0259372\n",
      "[20]\tcv_agg's binary_error: 0.180701 + 0.0274235\n",
      "[30]\tcv_agg's binary_error: 0.176193 + 0.021359\n",
      "[40]\tcv_agg's binary_error: 0.178428 + 0.0252489\n",
      "[50]\tcv_agg's binary_error: 0.173952 + 0.0149303\n",
      "[60]\tcv_agg's binary_error: 0.166087 + 0.0170612\n",
      "[70]\tcv_agg's binary_error: 0.164976 + 0.0189233\n",
      "[80]\tcv_agg's binary_error: 0.158241 + 0.0147091\n",
      "[90]\tcv_agg's binary_error: 0.166106 + 0.0130923\n",
      "[100]\tcv_agg's binary_error: 0.162716 + 0.0124947\n",
      "[110]\tcv_agg's binary_error: 0.161586 + 0.0144549\n",
      "[120]\tcv_agg's binary_error: 0.162716 + 0.011969\n",
      "[130]\tcv_agg's binary_error: 0.158228 + 0.0136617\n",
      "[140]\tcv_agg's binary_error: 0.160475 + 0.0112666\n",
      "[150]\tcv_agg's binary_error: 0.161593 + 0.0126621\n",
      "[160]\tcv_agg's binary_error: 0.162716 + 0.0143578\n",
      "[170]\tcv_agg's binary_error: 0.160482 + 0.0124245\n",
      "[180]\tcv_agg's binary_error: 0.163859 + 0.0124669\n",
      "[190]\tcv_agg's binary_error: 0.161612 + 0.0113643\n",
      "[200]\tcv_agg's binary_error: 0.163859 + 0.0124593\n",
      "\n",
      "best n_estimators: 154\n",
      "best cv-score: 0.15821553188237267\n"
     ]
    }
   ],
   "source": [
    "data_train=lgb.Dataset(data_X_train,data_y_train,silent=True)\n",
    "params={'boosting_type':'gbdt',\n",
    "        'objective':'binary',\n",
    "        'learning_rate':0.1,\n",
    "        'num_leaves':31,\n",
    "        'max_depth':5,        \n",
    "       }\n",
    "cv_results=lgb.cv(params,data_train,num_boost_round=1000,nfold=5,stratified=True,shuffle=True,metrics='binary_error',early_stopping_rounds=50,\\\n",
    "                  verbose_eval=10,show_stdv=True,seed=0)\n",
    "print ('\\nbest n_estimators:',len(cv_results['binary_error-mean']))\n",
    "print ('best cv-score:',cv_results['binary_error-mean'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['binary_error-mean', 'binary_error-stdv'])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#cv_results.items()\n",
    "# 第一次 search 粗略\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "model_lgb=lgb.LGBMClassifier(boosting_type='gbdt',num_leaves=31,max_depth=5,learning_rate=0.1,n_estimators=154,objective='binary',\\\n",
    "                             n_jobs=-1,silent=True,importance_type='split')\n",
    "param_grid1={'num_leaves':[15,28,31,45,64],'max_depth':[4,5,6]}\n",
    "gs1=GridSearchCV(model_lgb,param_grid=param_grid1,scoring='accuracy',iid='warn',n_jobs=-1,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "        importance_type='split', learning_rate=0.1, max_depth=5,\n",
       "        min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "        n_estimators=154, n_jobs=-1, num_leaves=31, objective='binary',\n",
       "        random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "        subsample=1.0, subsample_for_bin=200000, subsample_freq=0),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'num_leaves': [15, 28, 31, 45, 64], 'max_depth': [4, 5, 6]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs1.fit(data_X_train,data_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8338945005611672,\n",
       " LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "         importance_type='split', learning_rate=0.1, max_depth=5,\n",
       "         min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "         n_estimators=154, n_jobs=-1, num_leaves=15, objective='binary',\n",
       "         random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "         subsample=1.0, subsample_for_bin=200000, subsample_freq=0))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs1.best_score_,gs1.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.80446927, 0.79888268, 0.84831461, 0.82022472, 0.85310734])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# K折交叉验证\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores=cross_val_score(gs1,data_X_train,data_y_train,cv=5,n_jobs=-1,scoring='accuracy')\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8249997251565455"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "        importance_type='split', learning_rate=0.1, max_depth=5,\n",
       "        min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "        n_estimators=154, n_jobs=-1, num_leaves=31, objective='binary',\n",
       "        random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "        subsample=1.0, subsample_for_bin=200000, subsample_freq=0),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'num_leaves': [11, 13, 15, 17, 19], 'max_depth': [4, 5]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 第二次 search 精细\n",
    "param_grid2={'num_leaves':[11,13,15,17,19],'max_depth':[4,5]}\n",
    "gs2=GridSearchCV(model_lgb,param_grid=param_grid2,scoring='accuracy',iid='warn',cv=5)\n",
    "gs2.fit(data_X_train,data_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8338945005611672,\n",
       " LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "         importance_type='split', learning_rate=0.1, max_depth=5,\n",
       "         min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "         n_estimators=154, n_jobs=-1, num_leaves=15, objective='binary',\n",
       "         random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "         subsample=1.0, subsample_for_bin=200000, subsample_freq=0))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs2.best_score_,gs2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.79329609, 0.80446927, 0.85393258, 0.82022472, 0.85310734]),\n",
       " 0.8250060022264092)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores=cross_val_score(gs2,data_X_train,data_y_train,cv=5,scoring='accuracy')\n",
    "scores,scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_y_lgb_pred=gs2.predict(test_data_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data_origin['Survived']=np.where(test_y_lgb_pred.ravel()>0.5,1,0)\n",
    "test_data_origin[['PassengerId','Survived']].to_csv('c:/users/dell/desktop/gender_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "        importance_type='split', learning_rate=0.1, max_depth=5,\n",
       "        min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "        n_estimators=154, n_jobs=-1, num_leaves=31, objective='binary',\n",
       "        random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "        subsample=1.0, subsample_for_bin=200000, subsample_freq=0),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'num_leaves': [14, 15, 16], 'n_estimators': [40, 151]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid3={'num_leaves':[14,15,16],\"n_estimators\":[40,151]}\n",
    "gs3=GridSearchCV(model_lgb,param_grid=param_grid3,scoring='accuracy',iid='warn',cv=5)\n",
    "gs3.fit(data_X_train,data_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8327721661054994,\n",
       " LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "         importance_type='split', learning_rate=0.1, max_depth=5,\n",
       "         min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "         n_estimators=151, n_jobs=-1, num_leaves=15, objective='binary',\n",
       "         random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "         subsample=1.0, subsample_for_bin=200000, subsample_freq=0))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs3.best_score_,gs3.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "尽管模型已经过拟合，但仍然没有达到我要的精度要求，在这种情况下，是什么问题呢？考虑数据的特征工程"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
